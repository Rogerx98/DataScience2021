{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "class6_HW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6af30b417a540d18b0b58a3e0ce323e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24d359f7755f4642bc3e1d00fb92ca58",
              "IPY_MODEL_b35617e9e30f4b9eab1dd0b5128bb8d6",
              "IPY_MODEL_59210bd7cc924b55a77a9f193234e7f6"
            ],
            "layout": "IPY_MODEL_b46158a6599940438a5bb2769f36f265"
          }
        },
        "24d359f7755f4642bc3e1d00fb92ca58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b51a0b50d994684bc5856505239c292",
            "placeholder": "​",
            "style": "IPY_MODEL_fb554a6ddd03482582e5f35d201236fc",
            "value": "Downloading: 100%"
          }
        },
        "b35617e9e30f4b9eab1dd0b5128bb8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d45e095d65c41ecaa7cbc30beee27db",
            "max": 536063208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ba83cc6568f44daa32b8664e10dc877",
            "value": 536063208
          }
        },
        "59210bd7cc924b55a77a9f193234e7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_737a7f304b784b6b8cd3bd84edf86ed4",
            "placeholder": "​",
            "style": "IPY_MODEL_10b04a2ca10a4f969afab7cc0c44f358",
            "value": " 511M/511M [00:09&lt;00:00, 62.6MB/s]"
          }
        },
        "b46158a6599940438a5bb2769f36f265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b51a0b50d994684bc5856505239c292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb554a6ddd03482582e5f35d201236fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d45e095d65c41ecaa7cbc30beee27db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba83cc6568f44daa32b8664e10dc877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "737a7f304b784b6b8cd3bd84edf86ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b04a2ca10a4f969afab7cc0c44f358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHiyjUKpWoLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e16a495-8fb9-4cbc-ea7a-b76826995111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 6.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#possibly replace with e.g. util.pytorch_cos_sim from sentence_transformers\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "from transformers import pipeline\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xh13fY4OVfPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwkB7DgnwOVv",
        "outputId": "5255a791-017b-4363-c1ca-db2b7d14376c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "#checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "sGGDVojIofKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "#checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "model = TFAutoModel.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "a6af30b417a540d18b0b58a3e0ce323e",
            "24d359f7755f4642bc3e1d00fb92ca58",
            "b35617e9e30f4b9eab1dd0b5128bb8d6",
            "59210bd7cc924b55a77a9f193234e7f6",
            "b46158a6599940438a5bb2769f36f265",
            "3b51a0b50d994684bc5856505239c292",
            "fb554a6ddd03482582e5f35d201236fc",
            "0d45e095d65c41ecaa7cbc30beee27db",
            "7ba83cc6568f44daa32b8664e10dc877",
            "737a7f304b784b6b8cd3bd84edf86ed4",
            "10b04a2ca10a4f969afab7cc0c44f358"
          ]
        },
        "id": "tKAkLq4XV4jF",
        "outputId": "b82188c2-31f1-4c62-da1b-6902527ec615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6af30b417a540d18b0b58a3e0ce323e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"BIPM alumni are in high demand!\"\n",
        "tokens = tokenizer.tokenize(s)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)\n",
        "\n",
        "ids2 = tokenizer(s, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "print(ids2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0kbx7uKWQm7",
        "outputId": "dc60d58b-1465-451a-e2a9-94cde2042f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12170, 9737, 9441, 2024, 1999, 2152, 5157, 999]\n",
            "{'input_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
            "array([[  101, 12170,  9737,  9441,  2024,  1999,  2152,  5157,   999,\n",
            "          102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = [\n",
        "    \"How does the dimension of the embedding come about\",\n",
        "    \"How do you come around?\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLIs7ZhTWlAQ",
        "outputId": "38eec5ac-2ee8-42a1-c13b-c487686e0bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(2, 13), dtype=int32, numpy=\n",
            "array([[ 101, 2129, 2515, 1996, 9812, 1997, 1996, 7861, 8270, 4667, 2272,\n",
            "        2055,  102],\n",
            "       [ 101, 2129, 2079, 2017, 2272, 2105, 1029,  102,    0,    0,    0,\n",
            "           0,    0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(2, 13), dtype=int32, numpy=\n",
            "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 13), dtype=int32, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]], dtype=int32)>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Import dataset\n",
        "TWSM_path=\"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "decoded_reviews = pickle.load(open(TWSM_path + \"data/IMDB/decoded_reviews_train.pkl\", \"rb\"))\n",
        "train_labels = pickle.load(open(TWSM_path + \"data/IMDB/train_labels.pkl\", \"rb\"))"
      ],
      "metadata": {
        "id": "OlkoKZ5aW0MN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the different ways of calling the tokenizer:"
      ],
      "metadata": {
        "id": "caOj_FxbDhJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tasks:\n",
        "\n",
        "1. Embedding Similarity \n",
        "  * Write a function that takes as input two sentences, finds identical words, computes their contextual embeddings and prints the cosine similarity.\n",
        "  * Ask interesting questions (case, punctuation,...)\n",
        "  * Use longer words and find similarity between sub words\n",
        "\n",
        "2. Load the IMBD reviews and sample 500 positive and negative reviews. \n",
        "  * Extract the embedding vectors\n",
        "  * Fit a Naive Bayes classifier"
      ],
      "metadata": {
        "id": "-UYvNTjElJhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding similaritiy"
      ],
      "metadata": {
        "id": "_483D6A7_HHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(s1,s2):\n",
        "  s = [s1,s2]\n",
        "  #find similar string\n",
        "  s1_split = s1.lower().split()\n",
        "  s2_split = s2.lower().split()\n",
        "  for w1 in s1_split:\n",
        "    for w2 in s2_split:\n",
        "      if w1 == w2:\n",
        "          print(w1,w2)\n",
        "\n",
        "  #tokenizing\n",
        "  input = tokenizer(s, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "  outputs = model(input)\n",
        "  \n",
        "  #convert tokenize to id\n",
        "  for i, s_t in enumerate(s):\n",
        "    tokens[i] = tokenizer.tokenize(s_t)\n",
        "    ids[i] = tokenizer.convert_tokens_to_ids(tokens[i])\n",
        "    \n",
        "\n",
        "  #find similar ids\n",
        "  id_similar, index1, index2 = np.intersect1d(ids[0], ids[1], return_indices=True)\n",
        "  #plus 1 bc input_ids always start with 101 as default\n",
        "  d = {\"s1\": index1+1, \"s2\": index2+1}\n",
        "  df = pd.DataFrame(d)\n",
        "\n",
        "  for i in range(df.shape[0]):\n",
        "    embed_1 = outputs.last_hidden_state[0,df.iloc[i,0],:]\n",
        "    embed_2 = outputs.last_hidden_state[1,df.iloc[i,1],:]\n",
        "    #print(embed_1,embed_2)\n",
        "    print(\"similarity:\")\n",
        "    print( 1 - cosine(embed_1, embed_2)) \n"
      ],
      "metadata": {
        "id": "nhAZEoFb_Uib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity(raw_inputs[0],raw_inputs[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh6Nj8vwlDkX",
        "outputId": "09a72ecb-8fe8-4f09-ad67-6f4dbe72d75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how how\n",
            "come come\n",
            "similarity:\n",
            "0.6776947379112244\n",
            "similarity:\n",
            "0.47551581263542175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs_2 = [\"Should we eat french fries?\", \"I want to learn French.\"]\n",
        "similarity(raw_inputs_2[0],raw_inputs_2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fPbyVA1ioMH",
        "outputId": "e87d7c79-96c0-40fb-f987-4d018b98fafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity:\n",
            "0.49993452429771423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs_3 = [\"Bark is the outermost layers of trees.\", \"Your dog bark very loudly.\"]\n",
        "similarity(raw_inputs_3[0],raw_inputs_3[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6-LKR8NjGVj",
        "outputId": "5a7c19ed-75de-45c0-cbd1-4784ff216a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bark bark\n",
            "similarity:\n",
            "0.22434386610984802\n",
            "similarity:\n",
            "0.3719160258769989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the IMBD reviews and sample 500 positive and negative reviews.\n",
        "\n",
        "- Extract the embedding vectors\n",
        "- Fit a Naive Bayes classifier"
      ],
      "metadata": {
        "id": "VAvLcxlKnK3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reload imdb\n",
        "ReloadIMDB=False\n",
        "\n",
        "if ReloadIMDB:\n",
        "  from tensorflow.keras.datasets import imdb\n",
        "  (train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "    num_words=10000)\n",
        "\n",
        "  word_index = imdb.get_word_index()\n",
        "  reverse_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "  \n",
        "  N=len(train_data)\n",
        "  decoded_reviews = [\"\" for x in range(N)]\n",
        "\n",
        "  for j in range(N):\n",
        "    decoded_reviews[j] = \" \".join(\n",
        "      [reverse_word_index.get(i - 3, \"?\") for i in train_data[j]])  \n",
        "    \n",
        "    N=len(test_data)\n",
        "  decoded_reviews_test = [\"\" for x in range(N)]\n",
        "\n",
        "  for j in range(N):\n",
        "    decoded_reviews_test[j] = \" \".join(\n",
        "      [reverse_word_index.get(i - 3, \"?\") for i in test_data[j]])\n",
        "    \n",
        "  pickle.dump(decoded_reviews_test, open(TWSM_path + \"data/IMDB/decoded_reviews_test.pkl\", \"wb\"))\n",
        "  pickle.dump(decoded_reviews, open(TWSM_path + \"data/IMDB/decoded_reviews_train.pkl\", \"wb\"))\n",
        "  pickle.dump(train_labels, open(TWSM_path + \"data/IMDB/train_labels.pkl\", \"wb\"))\n",
        "  pickle.dump(test_labels, open(TWSM_path + \"data/IMDB/test_labels.pkl\", \"wb\"))\n",
        "else:\n",
        "  decoded_reviews_test = pickle.load(open(TWSM_path + \"data/IMDB/decoded_reviews_test.pkl\", \"rb\"))\n",
        "  decoded_reviews = pickle.load(open(TWSM_path + \"data/IMDB/decoded_reviews_train.pkl\", \"rb\"))\n",
        "  train_labels = pickle.load(open(TWSM_path + \"data/IMDB/train_labels.pkl\", \"rb\"))\n",
        "  test_labels = pickle.load(open(TWSM_path + \"data/IMDB/test_labels.pkl\", \"rb\"))"
      ],
      "metadata": {
        "id": "_SlNrIfenM1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = 50\n",
        "\n",
        "#train data\n",
        "review_train = pd.DataFrame(decoded_reviews,train_labels).reset_index()\n",
        "review_train.columns = [\"labels\",\"reviews\"]\n",
        "#choose 500 pos & neg reviews\n",
        "r_train_pos = review_train[review_train[\"labels\"]==1].sample(size)\n",
        "r_train_neg = review_train[review_train[\"labels\"]==0].sample(size)\n",
        "r_train = pd.concat([r_train_pos,r_train_neg],axis=0)\n"
      ],
      "metadata": {
        "id": "t45DQvzMIcv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0spIbKWUNrY3",
        "outputId": "74f2a3cc-942a-4bb8-de2d-ee3d398a7173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "#checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "raw_inputs = r_train.reviews.tolist()\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC-TejHHPYt4",
        "outputId": "43bdb1e5-1274-40ee-b80b-25028b2f1279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(100, 512), dtype=int32, numpy=\n",
            "array([[ 101, 1029, 2023, ...,    0,    0,    0],\n",
            "       [ 101, 1029, 1045, ...,    0,    0,    0],\n",
            "       [ 101, 1029, 1045, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 101, 1029, 1999, ...,    0,    0,    0],\n",
            "       [ 101, 1029, 2568, ..., 1055, 2472,  102],\n",
            "       [ 101, 1029, 1045, ...,    0,    0,    0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(100, 512), dtype=int32, numpy=\n",
            "array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(100, 512), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "#checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "model = TFAutoModel.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42V0Xzx7TC1s",
        "outputId": "74e7de9b-177e-4203-e43d-c1670529fba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlFrcPhUS_D-",
        "outputId": "5f6fbb82-98bc-4cd9-d331-31fe6a8d3dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 512, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape to fit sclaer\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "X_train = outputs.last_hidden_state.reshape(size*2, 512*768)\n",
        "X_train_scaled = mms.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "RJ7qpnx1XC6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = r_train.labels.tolist()"
      ],
      "metadata": {
        "id": "K6-3UYascejL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SucYHpH4cUgN",
        "outputId": "925e8fe1-d5d8-4b38-a5f4-5605b466945c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "acc = accuracy_score(y_train, classifier.predict(X_train_scaled),normalize=True)\n",
        "print(\"Train accuracy is \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHtfg2ItdRTN",
        "outputId": "ad66c1cf-4a46-47ef-cc6f-c673b6523d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy is  0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare test data\n",
        "review_test = pd.DataFrame(decoded_reviews_test,test_labels).reset_index()\n",
        "review_test.columns = [\"labels\",\"reviews\"]\n",
        "\n",
        "#choose 500 pos & neg reviews\n",
        "r_test_pos = review_test[review_test[\"labels\"]==1].sample(size)\n",
        "r_test_neg = review_test[review_test[\"labels\"]==0].sample(size)\n",
        "r_test = pd.concat([r_test_pos,r_test_neg],axis=0)"
      ],
      "metadata": {
        "id": "L3bNuilFeS2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs_test = r_test.reviews.tolist()\n",
        "inputs = tokenizer(raw_inputs_test, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhAPKsIoexll",
        "outputId": "baf5947c-01f5-43a2-eab6-4dfde782e231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(100, 512), dtype=int32, numpy=\n",
            "array([[ 101, 1029, 2023, ...,    0,    0,    0],\n",
            "       [ 101, 1029, 1045, ...,    0,    0,    0],\n",
            "       [ 101, 1029, 2023, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 101, 1029, 2023, ...,    0,    0,    0],\n",
            "       [ 101, 1029, 7929, ...,    0,    0,    0],\n",
            "       [ 101, 1029, 1045, ...,    0,    0,    0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(100, 512), dtype=int32, numpy=\n",
            "array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(100, 512), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCK5FvTbe6g2",
        "outputId": "69caabbc-c14a-4afc-975d-eabe1140cf4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 512, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = outputs.last_hidden_state.reshape(size*2, 512*768)\n",
        "X_test_scaled = mms.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "uK8vX2P5fA0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = r_test.labels.tolist()"
      ],
      "metadata": {
        "id": "wNZaspm6fGyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test accuracy\n",
        "acc = accuracy_score(y_test, classifier.predict(X_test_scaled),normalize=True)\n",
        "print(\"Test accuracy is \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WskoBPdfOoT",
        "outputId": "852a9d87-1d39-4fd7-a482-c26c894e2d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is  0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = classifier.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "90YT5bP8fa3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(y_test,y_pred_test),annot=True,fmt='d')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "7HnYCAeCfeE3",
        "outputId": "7a3a0c14-9a8f-481b-a025-14ee400e1922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f67194d74d0>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AVhp-THIfjov"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}